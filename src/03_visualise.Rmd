---
title: "03_visualise"
author: "Alexandra Tidd"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    fig_width: 8
    keep_md: true
    code_folding: show
    toc: true
    toc_float: true
    toc_collapsed: true
    toc_depth: 4
    theme: lumen
---

```{r setup, include = F, message = F, warning = F, class.source = 'fold-hide'}
# module load R/4.4.0 ; Rscript -e "rmarkdown::render('src/03_visualise.Rmd', output_dir = 'out/analysis/')" # nolint: line_length_linter.

# knitr opts
knitr::opts_knit$set(root.dir = "../")
knitr::opts_chunk$set(warning = FALSE, dpi = 300, message = FALSE)

# dirs
nanoseq_dir <- "out/nanoseq/outNextflow/"
dir.create("out/analysis/", showWarnings = FALSE)

# libraries
library(magrittr)
library(ggplot2)

# colours and orders ####

# set order/colours of biopsy
# "The correct pathway within the nephron starts with the glomerulus followed
# by the Bowman's capsule, proximal convoluted tubule, the descending loop of
# Henle, the ascending loop of Henle, distal convoluted tubule, and collecting
# duct. The glomerulus is found within the Bowman's capsule.
phenotype_colours <-
  c(
    "glomerulus" = "#66A61E",
    "PCT" = "#E6AB02",
    "DCT" = "#D95F02",
    "lymphoid_aggregate" = "#7570B3",
    "endothelial" = "#E7298A",
    "tumour" = "black"
  )

# set order/colours of trinucleotide subs
trinuc_colours <-
  c(
    "C>A" = "deepskyblue",
    "C>G" = "black",
    "C>T" = "firebrick2",
    "T>A" = "gray",
    "T>C" = "darkolivegreen3",
    "T>G" = "rosybrown2"
  )


# functions ####

# function: get files in nanoseq dir from prefix
get_files <- function(biopsy_ids, ext) {
  files <-
    biopsy_ids %>%
    purrr::set_names(., .) %>%
    purrr::map(function(biopsy_id) {
      list.files(file.path(nanoseq_dir, biopsy_id),
        full.names = TRUE, pattern = ext, recursive = TRUE
      )
    }) %>%
    # remove empty elements
    Filter(length, .)

  if (grepl("tsv", ext) == TRUE) {
    # load tsv
    out <-
      files %>%
      purrr::map_df(function(file) {
        file %>%
          read.table() %>%
          tibble::as_tibble(rownames = "row")
      }, .id = "biopsy_id")
  } else if (grepl("vcf.gz", ext) == TRUE) {
    # load vcf
    out <-
      files %>%
      purrr::map_df(function(file) {
        vcfR::read.vcfR(file, verbose = FALSE)@fix %>%
          tibble::as_tibble() %>%
          # only get variants that pass
          dplyr::filter(FILTER == "PASS") %>%
          # count variants per biopsy
          dplyr::mutate(n = dplyr::n())
      }, .id = "biopsy_id")
  } else if (grepl("verifyBAMid.txt", ext) == TRUE) {
    out <-
      files %>%
      purrr::map_df(function(file) {
        readr::read_delim(file, delim = ":", skip = 3, show_col_types = FALSE,
                          col_names = c("x", "alpha")) %>%
          dplyr::select(alpha)
      }, .id = "biopsy_id")
  } else {
    stop("Extension not recognised")
  }

  # return
  return(out)
}

# function: plot trinuc distributions
plot_trinucs <- function(trinucs_df) {
  trinucs_df %>%
    ggplot(aes(x = trinuc, y = trint_subst_obs, fill = substitution)) +
    geom_col(width = 0.5) +
    scale_fill_manual(values = trinuc_colours) +
    theme_minimal() +
    theme(
      axis.text.x = element_text(
        angle = 90, hjust = 1, family = "courier",
        size = 5
      ),
      legend.position = "none",
      panel.grid = element_blank()
    ) +
    labs(x = "substitution", y = "observed mutation counts") +
    facet_grid(~ substitution, scales = "free_x")
}

# callable diploid genome size for genome-wide counts from Abascal et al., 2021
# https://doi.org/10.1038/s41586-021-03477-4
callable_diploid_genome_bp <- 5722652910
```

# Introduction

This script analyses the output from the `NanoSeq` pipeline for the project 
**NanoSeq - (CP) Normal and cancer-predisposed kidney (2731)**.

## Load metadata

```{r load_metadata}
# read canapps QC
qc <-
  readxl::read_xlsx("data/Cancer_Pipeline_Reports_SampleDetails.xlsx") %>%
  dplyr::transmute(biopsy_id = Sample, biopsy_coverage = `Seq X`)

# load nanoseq sample sheet
sample_sheet <-
  readr::read_csv("out/nanoseq/sample_sheet.csv")

# load pseudobulk sample sheet
pseudo_sample_sheet <-
  readr::read_csv("out/merged_normal_bams/sample_sheet.csv") %>%
  dplyr::filter(sample_tumour_status == "Normal") %>%
  dplyr::count(donor_id, name = "n_samples_pseudobulked")

# load biopsy metadata and reorder phenotypes
biopsy_metadata <-
  readr::read_tsv("out/metadata/biopsy_metadata.tsv") %>%
  # filter to those that finished the nanoseq pipeline
  dplyr::filter(file.exists(paste0("out/nanoseq/outNextflow/", biopsy_id,
                            "/post/", biopsy_id, ".indel.vcf.gz"))) %>%
  # refactor
  dplyr::mutate(biopsy_phenotype = factor(biopsy_phenotype,
    levels = names(phenotype_colours)
  )) %>%
  # add coverage
  dplyr::left_join(qc) %>%
  # add n pseudobulked
  dplyr::left_join(pseudo_sample_sheet)
```

## NanoSeq outputs

The output files from the NanoSeq pipeline are located in the `post/` directory.

```{bash}
# ls -d out/nanoseq/outNextflow/*/post/ | head -1 | xargs ls
```

burdens.csv

callvsqpos.csv

coverage.csv

mismatches.csv

PD43824u_ds0002.burden.masked-vs-unmasked.pdf

PD43824u_ds0002.cov.bed.gz

PD43824u_ds0002.cov.bed.gz.tbi

PD43824u_ds0002.DSC_errors_per_channel.pdf

PD43824u_ds0002.DSC_estimated_error_rates.pdf

PD43824u_ds0002.estimated_error_rates.tsv

PD43824u_ds0002.indel.vcf.gz

PD43824u_ds0002.indel.vcf.gz.tbi

PD43824u_ds0002.mismatches.subst_asym.pdf

PD43824u_ds0002.mismatches.subst_asym.tsv

PD43824u_ds0002.mismatches.trinuc-profile.pdf

PD43824u_ds0002.mut_burden.tsv

PD43824u_ds0002.muts.tsv

PD43824u_ds0002.muts.vcf.gz

PD43824u_ds0002.muts.vcf.gz.tbi

PD43824u_ds0002.SSC-mismatches-Both.triprofiles.tsv

PD43824u_ds0002.SSC-mismatches-Purine.triprofiles.tsv

PD43824u_ds0002.SSC-mismatches-Pyrimidine.triprofiles.tsv

PD43824u_ds0002.subst_asym_and_rates_binned.pdf

PD43824u_ds0002.subst_asym_binned.tsv

PD43824u_ds0002.subst_asym.pdf

PD43824u_ds0002.subst_asym.tsv

PD43824u_ds0002.trint_counts_and_ratio2genome.tsv

PD43824u_ds0002.trint_subs_obs_corrected.tsv

PD43824u_ds0002.trinuc-profiles.pdf

pyrvsmask.csv

readbundles.csv

variants.csv


According to the [NanoSeq GitHub](https://github.com/cancerit/NanoSeq), these
are the most relevant output files from the pipeline:

* `muts.vcf.gz / muts.tsv`: substitutions called in vcf and tsv format. "PASS" 
substitutions are those not filtered by the common SNP and noisy sites masks 
(see Genomic masks).

* `indels.vcf.gz`: indel calls

* `burden.masked-vs-unmasked.pdf`: estimated burden before and after filtering 
common SNPs. Provides a qualitative view on contamination.

* `mut_burden.tsv`: estimated substitution burden with Poisson confidence
intervals. The corrected burden shows the burden after normalizing observed 
trinucleotide frequencies to the genomic trinucleotide frequencies.

* `trinuc-profiles.pdf` / `trint_subs_obs_corrected.tsv` / 
`trint_counts_and_ratio2genome.tsv`: Trinucleotide substitution profiles 
(observed and corrected), using the trinucleotide substitution counts in 
`trint_subs_obs_corrected.tsv` and the normalization of trinucleotide 
frequencies in `trint_counts_and_ratio2genome.tsv`. Normalization is required 
because NanoSeq results are depleted of trinucleotides overlapping the 
restriction site and of CpGs due to extensive filtering of common SNPs.

* `cov.bed.gz`: large file containing the effective duplex coverage for each 
genomic site, also showing the trinucleotide context of each site. This file is 
required to to calculate burdens and substitution profiles in sets of specific 
genomic regions (e.g. highly expressed genes, heterochromatin, ...).

* `subst_asym.pdf` / `subst_asym_and_rates_binned.pdf` / `subst_asym_binned.tsv` 
/ `subst_asym.pvals` / `subst_asym.tsv`: These files are not generally needed 
for NanoSeq analysis. They were originally used to detect asymmetries in the 
original DuplexSeq & BotSeqS protocols.

* `mismatches.trinuc-profile.pdf` / `mismatches.subst_asym.pdf` / 
`mismatches.subst_asym.pvals` / `mismatches.subst_asym.tsv`: These files show 
the asymmetries and pyrimidine/purine-based trinucleotide substitution profiles 
for single-strand consensus calls. These profiles are useful to understand DNA 
damage during library preparation.

* `DSC_errors_per_channel.pdf` / `DSC_estimated_error_rates.pdf` / 
`estimated_error_rates.tsv` / `SSC-mismatches-Both.triprofiles.tsv` / 
`SSC-mismatches-Purine.triprofiles.tsv` / 
`SSC-mismatches-Pyrimidine.triprofiles.tsv`: Based on the independent error 
rates in the purine and pyrimidine channels (e.g. G>T and C>A), we calculate the 
probability of having independent errors affecting both strands and resulting in 
double-strand consensus.

# Post-processing

## Load the NanoSeq outputs

I want to visualise the counts and burdens of indels and SNVs, and to plot the
distribution of trinucleotide substitutions. First, we load the relevant files.

```{r load_post}
post <-
  list(
    "mut_burden" = ".mut_burden.tsv$",
    "trint_subs_obs_corrected" = ".trint_subs_obs_corrected.tsv$",
    "indel" = ".indel.vcf.gz$",
    "muts" = ".muts.vcf.gz$",
    "verifyBAMid" = "duplex.verifyBAMid.txt$"
  ) %>%
  purrr::map(~ get_files(sample_sheet$id, .x))
```

## Remove biospies missing key metadata

I will exclude biopsies missing key metadata that is important for downstream 
analyses (donor age, biopsy phenotype).

```{r remove_incomplete_md}
complete <-
  biopsy_metadata %>%
  # remove biopsies missing key metadata (phenotype, donor age)
  dplyr::filter(!is.na(donor_age), !is.na(biopsy_phenotype))
post <-
  post %>%
  purrr::map(function(df) {
    df %>% dplyr::filter(biopsy_id %in% complete$biopsy_id)
  })
```

## Remove contaminated biopsies

I also want to test for contamination. I load the `verifyBAMid.txt` files for
these biopsies. According to the 
[NanoSeq README](https://github.com/cancerit/NanoSeq/blob/develop/README.md), an
alpha of < 0.005 is acceptable. We filter out biopsies that do not meet this 
threshold.

```{r verify_bam_id}
non_contam <- post[["verifyBAMid"]] %>% dplyr::filter(alpha < 0.005)
post <-
  post %>%
  purrr::map(function(df) {
    dplyr::filter(df, biopsy_id %in% non_contam$biopsy_id)
  })
```

## Calculate burdens and genome-wide counts

We combine the burdens from SNVs and from indels into a single long-form
dataframe.

* The `variant_type` column is either `snv` or `indel`. 

* The `value_type` column denotes what the `value` column is measuring. `count` 
is the number of each mutation type, `total` is the number of sites sequenced, 
and `burden` is the proportion of all sites sequenced that are of that mutation 
type (i.e. `snv` or `indel`). `countgenome` is the projected number of
mutations of that type across the entire genome. `countgenomeyearly` is this 
value divided by the donor age. 

N.B. `total` values for indels and SNVs will be the same in each biopsy. 

Then, we calculate mutations per genome per year. From 
[Cagan et al. (2022)](https://www.nature.com/articles/s41586-022-04618-z):

> For each sample, the somatic mutation density (mutations per bp) was 
> calculated by dividing the somatic mutation burden (total number of mutations 
> called) by the analysable genome size for the sample (see 'Calculation of 
> analysable genome size'). The adjusted somatic mutation burden (number of 
> mutations per whole genome) was then calculated by multiplying the mutation 
> density by the total genome size of the species (see below). The somatic 
> mutation rate per year (mutations per genome per year) was obtained by 
> dividing this adjusted mutation burden by the age of the individual, expressed 
> in years (Supplementary Table 2). The expected ELB for each sample was 
> calculated by multiplying the somatic mutation rate by the estimated lifespan 
> of the species...

The diploid human genome size for GRCh37 is 
`r format(callable_diploid_genome_bp, nsmall = 0, big.mark = ",")` bp, so we
multiply the burdens by the full genome size to get mutations per genome. We
then divide by donor age. to get mutations per genome per year.

```{r get_burdens}
# get all burdens
burdens <-
  post[["mut_burden"]] %>%
  # get corrected substitutions
  dplyr::filter(row == "corrected") %>%
  # standardise names
  dplyr::transmute(biopsy_id,
    snv_count = muts, snv_burden = burden,
    total, snv_total = total, indel_total = total
  ) %>%
  dplyr::left_join(post[["indel"]] %>%
                     dplyr::select(biopsy_id, indel_count = n) %>%
                     dplyr::distinct()) %>%
  # get donor age
  dplyr::left_join(biopsy_metadata %>% dplyr::select(biopsy_id, donor_age)) %>%
  # calculate indel burden
  dplyr::mutate(indel_burden = indel_count / total) %>%
  # calculate genome-wide count + yearly genome-wide count
  dplyr::mutate(indel_countgenome = indel_burden * callable_diploid_genome_bp,
                indel_countgenomeyearly = indel_countgenome / donor_age,
                snv_countgenome = snv_burden * callable_diploid_genome_bp,
                snv_countgenomeyearly = snv_countgenome / donor_age) %>%
  # convert to long format
  tidyr::pivot_longer(
    cols = c(
      dplyr::ends_with("_count"),
      dplyr::ends_with("_burden"),
      dplyr::ends_with("_total"),
      dplyr::ends_with("_countgenome"),
      dplyr::ends_with("_countgenomeyearly")
    ),
    names_pattern = "([^.]+)\\_([^.]+)$",
    names_to = c("variant_type", "value_type")
  ) %>%
  # add metadata
  dplyr::left_join(biopsy_metadata)

# save burdens
burdens %>%
  saveRDS("out/analysis/burdens.rds")

# view sample
burdens %>%
  head() %>%
  knitr::kable()
```

### Totals, counts, burdens, and genome-wide counts vs biopsy ID

```{r plot_burdens_vs_biopsy, class.source = 'fold-hide', fig.width = 12, fig.height = 15}
# TODO: change this to facet by donor_id and then relabel to donor_age_facet
# (rather than facet directly by donor_age_facet, because there might be
# multiple donors with the same age)
burdens %>%
  dplyr::mutate(donor_id = forcats::fct_reorder(donor_id, donor_age,
                                                .na_rm = FALSE),
                donor_age_facet = paste0(donor_age, "yo")) %>%
  ggplot(aes(x = biopsy_id, y = value, fill = biopsy_phenotype)) +
  geom_col() +
  scale_x_discrete(guide = guide_axis(angle = -90)) +
  scale_fill_manual(values = phenotype_colours) +
  ggh4x::facet_nested(variant_type + value_type ~
      biopsy_phenotype + donor_age_facet,
    scales = "free", space = "free_x", remove_labels = "x"
  ) +
  theme_bw() +
  theme(panel.spacing = unit(0, "cm", data = NULL))
```

### Burdens, counts, and totals vs donor age

```{r plot_burden_vs_age, class.source = 'fold-hide'}
burdens %>%
  dplyr::filter(!is.na(donor_age)) %>%
  ggplot(aes(x = donor_age, y = value, colour = biopsy_phenotype)) +
  geom_point() +
  scale_x_discrete(guide = guide_axis(angle = -90)) +
  scale_colour_manual(values = phenotype_colours) +
  ggh4x::facet_nested(value_type ~ variant_type,
    scales = "free",
    space = "free_x"
  ) +
  theme_bw()
```

### Average burden per microstructure

```{r plot_avg_burden}
pdf("test.pdf", width = 7, height = 4)
burdens %>%
  dplyr::filter(value_type == "countgenomeyearly") %>%
  dplyr::group_by(biopsy_phenotype, variant_type) %>%
  dplyr::mutate(med_cg = median(value)) %>%
  ggplot(aes(x = tidytext::reorder_within(biopsy_phenotype, by = med_cg, within = variant_type), 
             y = value, fill = biopsy_phenotype, colour = biopsy_phenotype)) +
  geom_boxplot(alpha = 0.5) +
  geom_jitter(height = 0, width = 0.1, alpha = 0.7) +
  scale_fill_manual(values = phenotype_colours) +  
  scale_colour_manual(values = phenotype_colours) +
  facet_wrap(~ variant_type, scales = "free") +
  theme_bw() +
  theme(legend.position = "none") +
  tidytext::scale_x_reordered(guide = guide_axis(angle = -90)) +
  labs(x = "", y = "mutations per genome per year")
dev.off()
```

### Donor age, burdens, counts, and totals vs n pseudobulked samples

```{r plot_age_vs_n_pseudo}
burdens %>%
  dplyr::filter(!is.na(donor_age)) %>%
  ggplot(aes(x = donor_age, y = n_samples_pseudobulked,
             colour = biopsy_phenotype)) +
  geom_point() +
  scale_colour_manual(values = phenotype_colours) +
  theme_bw()
```

```{r plot_burden_vs_n_pseudo, fig.height = 4}
burdens %>%
  dplyr::filter(!is.na(donor_age), 
                value_type %in% c("countgenome", "countgenomeyearly")) %>%
  dplyr::mutate(
    facet = dplyr::case_when(value_type == "countgenome" ~
                               "mutations per genome",
                             value_type == "countgenomeyearly" ~
                               "mutations per genome per year")) %>%
  ggplot(aes(x = n_samples_pseudobulked, y = value,
             colour = biopsy_phenotype)) +
  geom_point() +
  scale_colour_manual(values = phenotype_colours) +
  ggh4x::facet_nested(facet ~ variant_type,
    scales = "free", space = "free_x", independent = "y") +
  labs(y = "") +
  theme_bw()
```

### Median burden per donor vs donor age, by variant type

```{r plot_med_burden_vs_age, class.source = 'fold-hide', fig.height = 3}
burdens %>%
  dplyr::filter(!is.na(donor_age)) %>%
  dplyr::group_by(donor_id, variant_type) %>%
  dplyr::mutate(median_value = median(value),
                n_biopsies = dplyr::n_distinct(biopsy_id)) %>%
  ggplot(aes(x = donor_age, y = median_value, colour = donor_predisposition,
             size = n_biopsies)) +
  geom_point() +
  facet_wrap(~ variant_type, scales = "free_y") +
  theme_bw()
```

## Signature analysis

### Trinucleotide signature distribution

Next, we perform signature analysis on the corrected trinucleotide distribution 
of the detected SNVs. First, we reformat the trinucleotide substitution output
and take a look at the distribution of trinucleotide substitutions.

```{r sig}
trinucs <-
  post[["trint_subs_obs_corrected"]] %>%
  dplyr::rename(substitution_long = row) %>%
  # add metadata
  dplyr::left_join(biopsy_metadata) %>%
  dplyr::mutate(
    # get substitution
    substitution = paste0(
      stringr::str_sub(substitution_long, 2, 2),
      ">",
      stringr::str_sub(substitution_long, 5, 5)),
    # get affected trinuc
    trinuc = stringr::str_sub(substitution_long, 1, 3)
  )
```

Now we can plot the trinucleotide distribution of substitutions in the data.

#### By donor x biopsy phenotype

Trinucleotide susbtitutions are plotted for each donor-x-biopsy phenotype. 
Counts in each donor-x-biopsy phenotype are summed.

```{r plot_trinuc_by_donor_x_phenotype, class.source = 'fold-hide', fig.height = 2.5, fid.width = 10}
trinucs %>%
  {
    split(., .$donor_id)
  } %>%
  purrr::map(function(df) {
    df %>%
      {
        split(., as.character(.$biopsy_phenotype))
      } %>%
      purrr::map(function(df2) {
        title <- paste0(
          unique(df2$donor_id), " ", unique(df2$biopsy_phenotype),
          "\n", dplyr::n_distinct(df2$biopsy_id), " biopsies, ",
          sum(df2$trint_subst_obs), " substitutions"
        )
        df2 %>%
          plot_trinucs() +
          theme(strip.text.y = element_text(angle = 0, hjust = 0, vjust = 0)) +
          ggtitle(title)
      })
  })
```

#### By donor

Trinucleotide substitutions are plotted for all biopsies of each donor. Counts 
in each biopsy are summed per donor.

```{r plot_trinucs_by_donor, class.source = 'fold-hide', fig.height = 2.5, fid.width = 10}
trinucs %>%
  {
    split(., .$donor_id)
  } %>%
  purrr::map(function(df) {
    title <- paste0(
      unique(df$donor_id),
      "\n", dplyr::n_distinct(df$biopsy_id), " biopsies, ",
      sum(df$trint_subst_obs), " substitutions"
    )
    df %>%
      plot_trinucs() +
      ggtitle(title)
  })
```

#### By biopsy phenotype

Trinucleotide substitutions are plotted for all patients for each biopsy
phenotype. Counts in each patient are summed per biopsy phenotype.

```{r plot_trinuc_by_biopsy_phenotype, class.source = 'fold-hide', fig.height = 2.5, fid.width = 10}
trinucs %>%
  {
    split(., .$biopsy_phenotype)
  } %>%
  purrr::map(function(df) {
    title <- paste0(
      unique(df$biopsy_phenotype),
      "\n", dplyr::n_distinct(df$biopsy_id), " biopsies, ",
      sum(df$trint_subst_obs), " substitutions"
    )
    df %>%
      plot_trinucs() +
      ggtitle(title)
  })
```

### Trinculeotide signature extraction

We will now perform signature extraction using the `sigfit` package. First, we 
prepare the inputs. 

```{r sigfit}
profiles <-
  post[["trint_subs_obs_corrected"]] %>%
  dplyr::transmute(biopsy_id, row, trint_onto_genome) %>%
  tidyr::pivot_wider(id_cols = "biopsy_id", names_from = "row",
                     values_from = "trint_onto_genome") %>%
  tibble::column_to_rownames("biopsy_id")
```

## Linear mixed-effects modelling

A linear mixed-effects model must be used to disentangle the relative effects of 
donor age and other covariates, including donor sex, donor diagnosis, donor 
predisposition, and biopsy phenotype (microstructure). This allows us to account
for structure within the dataset, such as having multiple biopsies from each 
donor and multiple donors with the same diagnosis. We must control for these 
underlying within-group correlations when generating the model to avoid 
pseudoreplication.

### Should my variables be fixed or random effects?

> In broad terms, fixed effects are variables that we expect will have an effect
> on the dependent/response variable: they're what you call explanatory 
> variables in a standard linear regression. In our case, we are interested in 
> making conclusions about how dragon body length impacts the dragon's test 
> score. So body length is a fixed effect and test score is the dependent 
> variable.
>
> On the other hand, random effects are usually grouping factors for which we
> are trying to control. They are always categorical, as you can't force R to
> treat a continuous variable as a random effect. A lot of the time we are not
> specifically interested in their impact on the response variable, but we know 
> that they might be influencing the patterns we see.
>
> In our particular case, we are looking to control for the effects of mountain
> range. We haven't sampled all the mountain ranges in the world (we have eight)
> so our data are just a sample of all the existing mountain ranges. We are not
> really interested in the effect of each specific mountain range on the test
> score: we hope our model would also be generalisable to dragons from other
> mountain ranges! However, we know that the test scores from within the ranges
> might be correlated so we want to control for that.
>
> The golden rule is that you generally want your random effect to have 
> **at least five levels**. This is because estimating variance on few data 
> points is very imprecise. If you only have 2-3 levels, the model will struggle 
> to partition the variance. 
> 
> In the end, the big questions are:
> 
> 1. What are you trying to make predictions about?
>
> 2. What is just variation (a.k.a. noise) that you need to control for?

First, we set up a linear mixed model with age as a fixed effect and patient as 
a random effect.

```{r}
# we treat countgenome as the response variable
lmm_dat <-
  burdens %>%
  dplyr::filter(value_type == "countgenome") %>%
  dplyr::transmute(genome_wide_count = value, biopsy_id, sample_id, donor_id,
                   donor_age, variant_type, biopsy_phenotype,
                   donor_predisposition, donor_diagnosis, donor_sex,
                   biopsy_coverage, 
                   donor_predisposition = !is.na(donor_predisposition)) %>%
  {split(., .$variant_type)}

# initiate list of models
lmms <- list()

# gwc vs age, with donor as a random effect
lmms[["gwc_vs_age"]] <-
  lmm_dat %>%
  purrr::map(function(df) {
    nlme::lme(genome_wide_count ~ donor_age,
              random = ~ 1 | donor_id,
              data = df, method = "ML")
  })

# add predisposition as a random effect
lmms[["gwc_vs_age_w_predisp"]] <-
  lmm_dat %>%
  purrr::map(function(df) {
    nlme::lme(genome_wide_count ~ donor_age + donor_predisposition,
              random = ~ 1 | donor_id,
              data = df, method = "ML")
  })

# compare models
c("snv", "indel") %>%
  purrr::map(function(i) {
    anova(lmms$gwc_vs_age_w_predisp[[i]], lmms$gwc_vs_age[[i]])
  })
# it does not improve the fitness of the model
```


```{r lm}
models <-
  burdens %>%
  {split(., .$variant_type)} %>%
  purrr::map(function(df) {
    df %>%
      dplyr::filter(value_type == "countgenome") %>%
      dplyr::select(sample_id, donor_id, donor_age, donor_sex, donor_diagnosis,
                    donor_predisposition, biopsy_phenotype, value) %>%
      # standardise explanatory variables (mean 0, sd 1) - this makes sure that
      # estimated coefficients are all on the same scale, making it easier to
      # compare effect sizes
      dplyr::mutate(
        dplyr::across(where(is.numeric),
                      ~ scale(.x, center = TRUE, scale = TRUE)[, 1],
                      .names = "scaled_{.col}"))
  })

# 1. fit a linear model
basic_lms <-
  models %>%
  purrr::map(function(df) {
    lm(value ~ scaled_donor_age, data = df)
  })

# plot the lm
models %>%
  purrr::map2(names(models), function(df, variant_type) {
    df %>%
      ggplot(aes(x = donor_age, y = value)) +
      geom_point() +
      geom_smooth(method = "lm") +
      ggtitle(variant_type)
  })

# 2. fit a linear mixed model
mixed_lms <-
  models %>%
  purrr::map(function(df) {
    lme4::lmer(value ~ scaled_donor_age +
                 (1|donor_id/sample_id) +
                 (1|biopsy_phenotype),
               data = df) %>% summary
  })
```
